version: "3"

services:
  mysql:
    container_name: mysql
    image: mysql:latest
    restart: always # 컨테이너가 종료되면 항상 재시작
    ports:
      - "3307:3306" # 호스트의 3307 포트와 컨테이너의 3306 포트를 연결
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MYSQL_DATABASE: ${DB_DATABASE}
      MYSQL_USER: ${DB_USERNAME}
      MYSQL_PASSWORD: ${DB_USER_PASSWORD}
      TZ: Asia/Seoul # 타임존을 서울로 설정

  redis:
    image: redis:alpine
    container_name: redis
    command: redis-server --port 6379
    hostname: redis
    restart: always
    ports:
      - "6379:6379"

  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:3.7.14-management-alpine # RabbitMQ 관리자 페이지를 사용하기 위해 alpine 버전 사용
    restart: always
    ports:
      - "5672:5672" # RabbitMQ 서버 포트
      - "15672:15672" # RabbitMQ 관리자 페이지 포트
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}

  django:
    container_name: django
    build:
      context: ./backend # Docker 빌드 컨텍스트를 backend 폴더로 설정
      dockerfile: Dockerfile # Dockerfile 경로
    restart: always
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/backend # 코드 변경을 반영하기 위해 호스트와 컨테이너 간에 소스코드 공유
      - staticfiles:/backend/static # static 파일을 호스트와 컨테이너 간에 공유
    depends_on:
      - mysql # mysql 컨테이너가 실행되고 나서 django 컨테이너가 실행되도록 설정
      - rabbitmq # rabbitmq 컨테이너가 실행되고 나서 django 컨테이너가 실행되도록 설정
      - redis # redis 컨테이너가 실행되고 나서 django 컨테이너가 실행되도록 설정
    logging:
      driver: "json-file" # 로그 드라이버를 json-file로 설정
      options:
        max-size: "10m" # 로그 파일의 최대 크기를 10MB로 설정
        max-file: "3" # 최대 3개의 로그 파일 보존
    environment:
      SECRET_KEY: ${SECRET_KEY}
      DB_DATABASE: ${DB_DATABASE}
      DB_USERNAME: ${DB_USERNAME}
      DB_USER_PASSWORD: ${DB_USER_PASSWORD}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      NAVER_CLIENT_ID: ${NAVER_CLIENT_ID}
      NAVER_CLIENT_SECRET: ${NAVER_CLIENT_SECRET}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_STORAGE_BUCKET_NAME: ${AWS_STORAGE_BUCKET_NAME}
      AWS_S3_REGION_NAME: ${AWS_S3_REGION_NAME}
    command: sh -c "/wait && pipenv run python manage.py makemigrations && pipenv run python manage.py migrate && pipenv run python manage.py collectstatic --no-input && pipenv run gunicorn -c gunicorn.conf.py config.asgi:application --bind 0.0.0.0:8000"

  celery_worker:
    container_name: celery_worker
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    ports: []
    volumes:
      - ./backend:/backend # 코드 변경을 반영하기 위해 호스트와 컨테이너 간에 소스코드 공유
    depends_on:
      - django
      - rabbitmq
    environment:
      SECRET_KEY: ${SECRET_KEY}
      DB_DATABASE: ${DB_DATABASE}
      DB_USERNAME: ${DB_USERNAME}
      DB_USER_PASSWORD: ${DB_USER_PASSWORD}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      NAVER_CLIENT_ID: ${NAVER_CLIENT_ID}
      NAVER_CLIENT_SECRET: ${NAVER_CLIENT_SECRET}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_STORAGE_BUCKET_NAME: ${AWS_STORAGE_BUCKET_NAME}
      AWS_S3_REGION_NAME: ${AWS_S3_REGION_NAME}
    command: sh -c "pipenv run celery -A config worker --loglevel=info"

  celery_beat:
    container_name: celery_beat
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    ports: []
    volumes:
      - ./backend:/backend # 코드 변경을 반영하기 위해 호스트와 컨테이너 간에 소스코드 공유
    depends_on:
      - django
      - rabbitmq
      - celery_worker
    environment:
      SECRET_KEY: ${SECRET_KEY}
      DB_DATABASE: ${DB_DATABASE}
      DB_USERNAME: ${DB_USERNAME}
      DB_USER_PASSWORD: ${DB_USER_PASSWORD}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      NAVER_CLIENT_ID: ${NAVER_CLIENT_ID}
      NAVER_CLIENT_SECRET: ${NAVER_CLIENT_SECRET}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_STORAGE_BUCKET_NAME: ${AWS_STORAGE_BUCKET_NAME}
      AWS_S3_REGION_NAME: ${AWS_S3_REGION_NAME}
    command: sh -c "pipenv run celery -A config beat --loglevel=info"

  frontend:
    container_name: frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      - django # django 컨테이너가 실행되고 나서 frontend 컨테이너가 실행되도록 설정

  nginx:
    container_name: nginx
    build:
      context: ./nginx
      dockerfile: Dockerfile # Dockerfile 경로
    ports:
      - "80:80"
    depends_on:
      - django # django 컨테이너가 실행되고 나서 nginx 컨테이너가 실행되도록 설정
      - frontend # frontend 컨테이너가 실행되고 나서 nginx 컨테이너가 실행되도록 설정
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf # 호스트의 nginx 폴더와 컨테이너의 /etc/nginx/conf.d 폴더를 공유
      - staticfiles:/staticfiles # static 파일을 호스트와 컨테이너 간에 공유

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/config:/etc/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    restart: always
    depends_on:
      - django

  influxdb:
    image: bitnami/influxdb:latest
    container_name: influxdb
    ports:
      - "8086:8086"
      - "8085:8088"
    environment:
      INFLUXDB_ADMIN_USER_PASSWORD: ${DB_USER_PASSWORD}
      INFLUXDB_ADMIN_USER_TOKEN: ${DB_USERNAME}
      INFLUXDB_HTTP_AUTH_ENABLED: "false"
      INFLUXDB_DB: ${DB_DATABASE}

  grafana:
    container_name: grafana
    image: grafana/grafana:8.2.2
    restart: unless-stopped
    environment:
      GF_INSTALL_PLUGINS: "grafana-clock-panel"
      GF_DATABASE_TYPE: "mysql"
      GF_DATABASE_HOST: "mysql:3306"
      GF_DATABASE_NAME: ${DB_DATABASE}
      GF_DATABASE_USER: ${DB_USERNAME}
      GF_DATABASE_PASSWORD: ${DB_USER_PASSWORD}
    ports:
      - "3050:3000"
    volumes:
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini:ro
      - grafana-data:/var/lib/grafana
    logging:
      driver: "json-file"
      options:
        max-size: "8m"
        max-file: "10"

volumes:
  staticfiles: {}
  grafana-data: {}
